{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. Introducción y Objetivo\n",
        "El principal objetivo del actual proyecto es poder predecir el **precio de las viviendas en Ames**, basandose en las caracteristicas que el dataset ofrece.\n",
        "\n",
        "Entre el objetivo:\n",
        "- Seleccionar las variables principales.\n",
        "- Entrenar un modelo de regresión.\n",
        "- Medir el desempeño del modelo.\n",
        "- Realizar un analisis acerca de cuales fueron las variables que mayor impacto tuvieon en el precio final de la vivienda."
      ],
      "metadata": {
        "id": "fzHBbRoBOkb3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Importar Librerías\n"
      ],
      "metadata": {
        "id": "qui9PB2CPjCQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, auc, roc_auc_score\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "metadata": {
        "id": "Gfey1hkQPrWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Carga de Datos\n"
      ],
      "metadata": {
        "id": "CTl3YBBXQDEp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://raw.githubusercontent.com/Aaronruizdiaz/ProyectoDSParteI-RuizDiaz.ipynb/refs/heads/main/AmesHousing.csv'\n",
        "\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "df.shape\n",
        "df.head()"
      ],
      "metadata": {
        "id": "3lE6hvCeQRz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "NZicQNOKS8iN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "kNqK83zJTIEP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Hipótesis\n",
        "\n",
        "El tamaño de la vivienda (superficie total) y la calidad de construcción\n",
        "son los factores que más influyen en el precio de venta (SalePrice).\n",
        "\n",
        "La hipótesis planteada es que el tamaño de la vivienda, es decir la superficie total y la calidad de la construcción son los factores mas relevanes en el precio e venta o **SalePrice**"
      ],
      "metadata": {
        "id": "JXO4d6vyUiuS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Análisis Exploratorio de Datos (EDA)\n"
      ],
      "metadata": {
        "id": "BkkLZzOvVAJd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.1. Revisar valores faltantes"
      ],
      "metadata": {
        "id": "MOSQXO-qVDlZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "missing_values = df.isnull().sum()\n",
        "missing_values"
      ],
      "metadata": {
        "id": "-mA0j_b-VTmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Como mi columnas no son todas numericas no puedo reemplazar todos los Nulos por una variable numérica como lo es la mediana.\n",
        "# Es por esto que para las columnas numéricas utilizaremos la mediana mientras que para las columnas que no son numericas usaremos la moda.\n",
        "\n",
        "# Columnas numéricas - acá usamos la mediana\n",
        "num_columnas= df.select_dtypes(include=np.number).columns # para extraer solo las columnas con datos numéricos.\n",
        "df[num_columnas] = df[num_columnas].fillna(df[num_columnas].median()) # rellenamos los NaN con la mediana\n",
        "\n",
        "# Columnas categóricas - acá el valor que mas se repite, la moda\n",
        "df[cat_columnas] = df[cat_columnas].fillna(df[cat_columnas].mode())"
      ],
      "metadata": {
        "id": "gfuaTTB0V_bI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Como mi columnas no son todas numericas no puedo reemplazar todos los Nulos por una variable numérica como lo es la mediana.\n",
        "# Es por esto que para las columnas numéricas utilizaremos la mediana mientras que para las columnas que no son numericas usaremos la moda.\n",
        "\n",
        "# Columnas numéricas - acá usamos la mediana\n",
        "num_columnas = df.select_dtypes(include=np.number).columns\n",
        "df[num_columnas] = df[num_columnas].fillna(df[num_columnas].median())\n",
        "\n",
        "# Columnas categóricas - acá el valor que mas se repite, la moda\n",
        "cat_columnas = df.select_dtypes(exclude=np.number).columns\n",
        "for col in cat_columnas:\n",
        "    df[col] = df[col].fillna(df[col].mode()[0])"
      ],
      "metadata": {
        "id": "15K9F_DgCRwt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.2. Distribución de la variable objetivo ('target')"
      ],
      "metadata": {
        "id": "XePv0v5-anNm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# En este bloque vamos analizar nuestra variable Target.\n",
        "# Para esto tenemos un histograma que grafica la distribución de precios.\n",
        "\n",
        "sns.histplot(df['SalePrice'])\n",
        "plt.title(\"Distribución de SalePrice\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HBWN6FQiao_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.3. Análisis de variables numéricas"
      ],
      "metadata": {
        "id": "7XaXZAcFbPCw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_features = df.select_dtypes(include=np.number).columns.tolist()\n",
        "numerical_features"
      ],
      "metadata": {
        "id": "mshEM52KbPow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vamos a listar todas las columnas codificadas numericamente\n",
        "numerical_features = df.select_dtypes(include=np.number).columns.tolist()\n",
        "\n",
        "# Utilizando solamente las numéricas continuas realizamos histogramas.\n",
        "df[numerical_continuous].hist(figsize=(12, 8), bins=20)\n",
        "plt.suptitle('Histogramas de Variables Numéricas Continuas', y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "1L_0rbi-FJUk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vamos a chequear la relación entre las variables numericas y nuestra variable TArget.\n",
        "print(\"\\nScatterplots de Variables Numéricas Continuas vs SalePrice:\")\n",
        "\n",
        "for col in numerical_continuous:\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    sns.scatterplot(x=col, y='SalePrice', data=df, alpha=0.5) # Elegimos un scatterplot para detectar tendencias.\n",
        "    plt.title(f'{col} vs SalePrice')\n",
        "    plt.xlabel(col)\n",
        "    plt.ylabel('SalePrice')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "zZ232fVgIq98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.4. Análisis de variables categóricas"
      ],
      "metadata": {
        "id": "gRaTPCCaKWjn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_features = df.select_dtypes(include=['object']).columns.tolist()\n",
        "categorical_coded_num = ['OverallQual', 'OverallCond', 'MoSold', 'YrSold'] # Incluimos las que son codificadas numericamente\n",
        "categorical_features = categorical_coded_num + df.select_dtypes(include=['object']).columns.tolist()"
      ],
      "metadata": {
        "id": "66Nqoe39KXYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "sns.countplot(x='Overall Qual', data=df, hue='Sale Condition')\n",
        "plt.title('Cantidad de casas por OverallQual y SaleCondition')\n",
        "plt.xlabel('OverallQual (Calidad de la casa)')\n",
        "plt.ylabel('Cantidad de casas')\n",
        "plt.legend(title='Grupo de venta')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1cPKKC6tO05Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Feature Engineering (Ingeniería de Características)"
      ],
      "metadata": {
        "id": "A1Ge0v8EQnmk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear nuevas caracteristicas para nuestro Dataframe, en este caso la antiguedad de la casa\n",
        "bins = [0, 1950, 1970, 1990, 2010, df['Year Built'].max() +1]\n",
        "labels = ['Muy Vieja', 'Vieja', 'Media', 'Reciente', 'Muy Reciente']\n",
        "df['AgeGroup'] = pd.cut(df['Year Built'], bins=bins, labels=labels, right=False)"
      ],
      "metadata": {
        "id": "F9OinJUMQobZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[['Year Built', 'AgeGroup']].head()"
      ],
      "metadata": {
        "id": "-TedjJGFSXFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Realizamos un gráfico tipo Countplot donde comparamos nuestra nueva característica\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.countplot(x='AgeGroup', data=df, hue='Sale Condition')\n",
        "plt.title('Distribución de Grupos de Antigüedad por Grupo')\n",
        "plt.xlabel('Grupo de Antigüedad de la Casa')\n",
        "plt.ylabel('Cantidad de Casas')\n",
        "plt.legend(title='Grupo de venta', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dPa1QNt6Sg2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista completa de características a usar (sin 'SalePrice')\n",
        "# Numéricas:\n",
        "Features = df.select_dtypes(include=np.number).columns.tolist()\n",
        "Target = 'SalePrice'\n",
        "\n",
        "# Variables categóricas + nuestra nueva variable:\n",
        "categorical_features_for_encoding = categorical_features + ['AgeGroup']\n",
        "\n",
        "print(f\"\\nCaracterísticas numéricas a escalar: {numerical_features_for_scaling}\")\n",
        "print(f\"Características categóricas a codificar (OneHot): {categorical_features_for_encoding}\")\n",
        "print(f\"Variable objetivo: {target}\")"
      ],
      "metadata": {
        "id": "i0V2aNAaUP_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Preprocesamiento de Datos"
      ],
      "metadata": {
        "id": "oJGyHzSaVuHG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos las características x y variable objetivo y\n",
        "X = df[Features]\n",
        "y = df['SalePrice']"
      ],
      "metadata": {
        "id": "qpFPBsk-Vumm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numerical_features_for_scaling),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features_for_encoding)\n",
        "    ],\n",
        "    remainder='passthrough'\n",
        ")"
      ],
      "metadata": {
        "id": "YyHec3eGtyFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos el procesador\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numerical_features_for_scaling),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features_for_encoding)\n",
        "    ],\n",
        "    remainder='passthrough'  # Si hubiera columnas no especificadas, las dejaría pasar\n",
        ")"
      ],
      "metadata": {
        "id": "V700Nb3PXQ4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor"
      ],
      "metadata": {
        "id": "-9PSaxDkX3oK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. División de Datos (Train/Test Split)"
      ],
      "metadata": {
        "id": "IRPKzQvjYIrY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividir los datos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "\n",
        "print(f\"Tamaño del conjunto de entrenamiento (X_train): {X_train.shape}\")\n",
        "print(f\"Tamaño del conjunto de prueba (X_test): {X_test.shape}\")\n",
        "print(f\"Tamaño del conjunto de entrenamiento (y_train): {y_train.shape}\")\n",
        "print(f\"Tamaño del conjunto de prueba (y_test): {y_test.shape}\")"
      ],
      "metadata": {
        "id": "9_kroP4UYmfE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nDistribución de la variable objetivo en Train vs Test:\")\n",
        "print(f\"Train: \\n{y_train.value_counts(normalize=True)}\")\n",
        "print(f\"Test: \\n{y_test.value_counts(normalize=True)}\")"
      ],
      "metadata": {
        "id": "nbsVOMRzhQQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Construcción y Entrenamiento del Modelo (Random Forest)"
      ],
      "metadata": {
        "id": "TLtb55ZkhVKD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# En este bloque tuvimos que redefinir las variables numéricas y las categóricas\n",
        "# Porque encontramos errores en los nombres que generaban problemas.\n",
        "\n",
        "\n",
        "target = 'SalePrice'\n",
        "\n",
        "# Columnas numéricas y categóricas\n",
        "numerical_features_for_scaling = df.select_dtypes(include=np.number).columns.tolist()\n",
        "if target in numerical_features_for_scaling:\n",
        "    numerical_features_for_scaling.remove(target)\n",
        "\n",
        "categorical_features_for_encoding = df.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "# Columnas numéricas como categóricas\n",
        "categorical_coded_num = ['Overall Qual', 'Overall Cond', 'Mo Sold', 'Yr Sold']\n",
        "\n",
        "# Sacamos las que estaban duplicadas\n",
        "numerical_features_for_scaling = [col for col in numerical_features_for_scaling if col not in categorical_coded_num]\n",
        "categorical_features_for_encoding += categorical_coded_num\n",
        "categorical_features_for_encoding = list(set(categorical_features_for_encoding))\n",
        "\n",
        "# Filtramos\n",
        "numerical_features_for_scaling = [col for col in numerical_features_for_scaling if col in df.columns]\n",
        "categorical_features_for_encoding = [col for col in categorical_features_for_encoding if col in df.columns]\n",
        "\n",
        "# Ahora si trabajamos con el procesador\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numerical_features_for_scaling),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features_for_encoding)\n",
        "    ],\n",
        "    remainder='passthrough'\n",
        ")\n",
        "\n",
        "# Re Dividimos los daros\n",
        "X = df[numerical_features_for_scaling + categorical_features_for_encoding]\n",
        "y = df[target]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "\n",
        "# Pipeline\n",
        "\n",
        "model_pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('regressor', RandomForestRegressor(n_estimators=100, random_state=42))\n",
        "])\n",
        "\n",
        "# -------------------------------\n",
        "# 7. Entrenar el Pipeline completo\n",
        "model_pipeline.fit(X_train, y_train)\n",
        "\n",
        "print(\"Modelo entrenado correctamente\")\n"
      ],
      "metadata": {
        "id": "FUxv9NdfuwH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenar el pipeline completo (preprocesamiento + modelo)\n",
        "model_pipeline.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "_5YGY93rw2A3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. Evaluación del Modelo"
      ],
      "metadata": {
        "id": "OHBz7PzCxBea"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Realizar predicciones en el conjunto de prueba\n",
        "y_pred = model_pipeline.predict(X_test)"
      ],
      "metadata": {
        "id": "gxdCrhJExB-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Utilizando metricas de regresión vamos a evaluar el modelo\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_pred) # Métricas\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"Evaluación del Modelo Regresión\")\n",
        "print(f\"MAE  : {mae:.2f}\")\n",
        "print(f\"MSE  : {mse:.2f}\")\n",
        "print(f\"RMSE : {rmse:.2f}\")\n",
        "print(f\"R²   : {r2:.4f}\")\n"
      ],
      "metadata": {
        "id": "Efec538yxgdF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10.1 Errores de predicción"
      ],
      "metadata": {
        "id": "njPbpM0gzZb8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Permite evaluar errores, lo que no esta cerca de la linea roja estaría mal\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(y_test, y_pred, alpha=0.6)\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
        "plt.xlabel('Valores Reales')\n",
        "plt.ylabel('Valores Predichos')\n",
        "plt.title('Valores Reales vs Predichos')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ejbaFj6WzSak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. Conclusiones"
      ],
      "metadata": {
        "id": "H38XqlFT2v6x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nValidación de Hipótesis:\")\n",
        "print(f\"- Hipótesis: Las características 'GrLivArea', 'Overall Qual' y 'Neighborhood' influyen significativamente en el precio de las casas.\")\n",
        "print(f\"- Las 10 variables más importantes incluyen: {Features}\")\n",
        "print(f\"- R² del modelo en conjunto de prueba: {r2:.4f}\")\n",
        "print(f\"- MAE del modelo: {mae:.2f}\")\n",
        "print(\"- Hipótesis: Las características 'GrLivArea', 'Overall Qual' y 'Neighborhood'son las mas influyentes en el precio de las casas.\")\n",
        "print(\"- Luego de ver las 10 variables mayores podes determinar si tienen relevancia.\")\n",
        "print(\"- Los gráficos des permiten saber si el modelo esta correcto\")"
      ],
      "metadata": {
        "id": "3LAurntD2rXB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}